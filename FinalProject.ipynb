{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong><h3>Group Members</h3></strong><br>\n",
    "<strong>Yifei Wang</strong> A14006863<br>\n",
    "<strong>Xuyuan Duan</strong> A14059172<br>\n",
    "<strong>Tianyi Cao</strong> A13561380<br>\n",
    "<strong>Mingqi Shen</strong> A13687448<br>\n",
    "<strong>Junqi Hu</strong> A13763761<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong><h3>Research Question</h3></strong><br>\n",
    "    How is house price summarized by the location, time periods in a year, and the average number of rooms per household? How about the relationship between those factors and the house rent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong><h3>Hypothesis</h3></strong><br>\n",
    "    Housing price is correlated to the proximity to ocean, the time period, and the average number of rooms per household. Housing price will be higher in specific time periods in a year. We predict that:\n",
    "<br>\n",
    "1.More average rooms at the certain location means higher house pricing.<br>\n",
    "2.Closer proximity to ocean means higher house pricing.<br>\n",
    "3.Housing price will be higher in the fall of the year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong><h3>Dataset</h3></strong><br>\n",
    "Dataset Name: California Housing Prices<br>\n",
    "Link to the dataset: https://www.kaggle.com/camnugent/california-housing-prices/datad<br>\n",
    "Number of observations: 20641<br>\n",
    "This dataset describes the median house prices for California districts derived from the 1990 census. We are going to use the data after 2000.<br>\n",
    "<br>\n",
    "Dataset Name: Price to Rent Ratio, based on neighborhood<br>\n",
    "Link to the dataset: http://files.zillowstatic.com/research/public/Neighborhood/Neighborhood_PriceToRentRatio_AllHomes.csv<br>\n",
    "Number of observations: 5827<br>\n",
    "This dataset is from Zillow, which is about the rent to house ratio (the monthly rent divided by the house price) in different neighborhood in the United States.<br>\n",
    "<br>\n",
    "As mentioned above, the first dataset does not contain the information for the relationship between price and time period. Thus, we would need this supplemental information from the second dataset about the ratio of house price to rent in different places."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong><h3>Background and Prior Work</h3></strong><br>\n",
    "House price is an overall problem for most people in the United States. As international students, we usually need to evaluate housing price around the campus and then choose a house or an apartment with reasonable price carefully. In the process of finding our future home, we are interested in when and where the house price is at the lowest in order to save money as well as how to find such information.\n",
    "<br>\n",
    "This situation leads to our research question -- How is house price summarized by the location, time periods in a year, and the average number of rooms per household? Based on our experience of looking for apartments, the prices around May and June are typically at the highest, given the academic calendar our university has. The prior work described in the first reference “House Price Data Analysis” also shed a light to our entering point. This research relates the sale price to many variables and deduces that the sale price follows the skewed normal distribution.\n",
    "<br>\n",
    "References (include links):\n",
    "<br>\n",
    "1) Chandrashekhar, \"House Price Data Analysis\". The link is: https://www.kaggle.com/c7shekhar/house-price-data-analysis<br>\n",
    "2) Kenneth Richard Corsini, \"Statistical Analysis of Residential Housing Prices in An Up and Down Real Estate Market: A General Framework and Study of Cobb County, GA\". The link is: https://smartech.gatech.edu/bitstream/handle/1853/31763/Corsini_Kenneth_R_200912_mast.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import the packages we need to process the datasets\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read the csv file 'housing.csv' into a DataFrame called df_housing\n",
    "#read the csv file Neighborhood_PriceToRentRatio_AllHomes.csv' into a DataFrame called df_neighborhood\n",
    "\n",
    "df_housing = pd.read_csv('data/housing.csv')\n",
    "df_neighborhood = pd.read_csv('data/Neighborhood_PriceToRentRatio_AllHomes.csv')\n",
    "\n",
    "#locate the 326th row of df_neighborhood and create another DataFrame containing called df_laJolla\n",
    "\n",
    "df_laJolla = df_neighborhood.iloc[[326]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong><h3>Data Cleaning (Part1)</h3></strong><br>\n",
    "The first dataset aims at finding the relationship between ocean proximity and house value with only the latitude and longitude to represent the location. Thus, we would like to use the google api to transform these coordinates into actual neighborhood names. There are some places whose values of latitude and longitude were not recognized as existed neighborhood names, so we would like to drop these rows. Due to the limiting use of geocode api, we could only analyse the first 6000 data of our dataset. After finishing manipulating the data, we markdown the process and save the output into a new csv. Furthermore, we would like to drop the outliers with house value greater than 450000, like we indicated in the proposal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#use google api to get address json data from latitude and longitude\n",
    "\n",
    "response = pd.read_json(orient='values', path_or_buf=\"https://maps.googleapis.com/maps/api/geocode/json?latlng=32.757,-117.1611&result_type=neighborhood&key=AIzaSyD9kCp8gixKsqC6W7JwPZ05F2aCTraGgZQ\")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#tranform the dataframe into dictionary and trim the data\n",
    "\n",
    "responseDict = response['results'][0]\n",
    "responseDict = responseDict['address_components']\n",
    "responseDict = responseDict[0]\n",
    "responseDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#get the neighborhood name\n",
    "\n",
    "neighborhood = responseDict['long_name']\n",
    "neighborhood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#write a function to take longitute and latitude as parameters and return the neighborhood name\n",
    "#one key is limited to 2500 times of uses of api\n",
    "\n",
    "def getNeighborhood(latitude, longitude, key):\n",
    "    long = str(longitude)\n",
    "    lati = str(latitude)\n",
    "    key = str(key)\n",
    "    \n",
    "    #use google api to get address json data from latitude and longitude\n",
    "    \n",
    "    response = pd.read_json(orient='values', path_or_buf=\"https://maps.googleapis.com/maps/api/geocode/json?latlng=\"+lati+\",\"+long+\"&result_type=neighborhood&key=\"+key)\n",
    "    \n",
    "    #tranform the dataframe into dictionary and trim the data\n",
    "    \n",
    "    responseDict = response['results'][0]\n",
    "    responseDict = responseDict['address_components']\n",
    "    responseDict = responseDict[0]\n",
    "    \n",
    "    #get the neighborhood name\n",
    "    \n",
    "    neighborhood = responseDict['long_name']\n",
    "    return neighborhood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#test\n",
    "\n",
    "getNeighborhood(37.85, -122.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#construct a list of neightborhoods by their coordinates in housing dataframe\n",
    "\n",
    "neighborhoodList = []\n",
    "\n",
    "#different keys\n",
    "\n",
    "key1=\"AIzaSyAgF8fiO9Zrqv2UFUN49QbGVlyOZM4kwA0\"\n",
    "key2=\"AIzaSyDaiw34am9uDbCrTPKuCSkaeFk99wr-O4M\"\n",
    "key3=\"AIzaSyCwc3jjVKCI0ZJHrrJTNBK8yoFkw9YdJvc\"\n",
    "\n",
    "#due to the limit only process 2000 per key\n",
    "\n",
    "#key1\n",
    "\n",
    "for i in range (0, 1999):\n",
    "    try:\n",
    "        \n",
    "        #use different keys\n",
    "        \n",
    "        neighborhoodList.append(getNeighborhood(df_housing['latitude'][i], df_housing['longitude'][i], key1))\n",
    "    except:\n",
    "        \n",
    "        #neighborhood not found\n",
    "        \n",
    "        neighborhoodList.append(\"none\")\n",
    "\n",
    "#key2\n",
    "\n",
    "for i in range (2000, 3999):\n",
    "    try:\n",
    "        \n",
    "        #use different keys\n",
    "        \n",
    "        neighborhoodList.append(getNeighborhood(df_housing['latitude'][i], df_housing['longitude'][i], key2))\n",
    "    except:\n",
    "        \n",
    "        #neighborhood not found\n",
    "        \n",
    "        neighborhoodList.append(\"none\")\n",
    "\n",
    "#key3\n",
    "\n",
    "for i in range (4000, 5999):\n",
    "    try:\n",
    "        \n",
    "        #use different keys\n",
    "        \n",
    "        neighborhoodList.append(getNeighborhood(df_housing['latitude'][i], df_housing['longitude'][i], key3))\n",
    "    except:\n",
    "        \n",
    "        #neighborhood not found\n",
    "        \n",
    "        neighborhoodList.append(\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "neighborhoodList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#creat a pandas dataframe and save to csv\n",
    "\n",
    "df_neighborhoodList = pd.DataFrame(neighborhoodList)\n",
    "df_neighborhoodList.to_csv(\"df_neighborhoodList.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "#import the csv file 'df_neighborhoodList.csv' into a DataFrame called df_neighborhoodList\n",
    "\n",
    "df_neighborhoodList = pd.read_csv(\"df_neighborhoodList.csv\")\n",
    "df_housingNew = df_housing.head(n = 6000)\n",
    "df_housingNew['neighborhood'] = df_neighborhoodList['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the rows that did not return a neighborhood using geocode\n",
    "#drop rows that contain NaN\n",
    "#drop rows whose median house value is greater than 450000\n",
    "\n",
    "df_housingNew = df_housingNew[df_housingNew['neighborhood']!= 'none']\n",
    "df_housingNew = df_housingNew.dropna()\n",
    "df_housingNew[df_housingNew['median_house_value'] <= 450000]\n",
    "\n",
    "#reset the index of the dataframe\n",
    "df_housingNew = df_housingNew.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong><h3>Data Analysis (Part1)</h3></strong><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "#run a for loop to transform the string to float (e.g. \"NEAR BAY\" to 0.0, \"<1H OCEAN\" to 0.5, and all others to 1.0)\n",
    "\n",
    "for i in range(0, len(df_housingNew)):\n",
    "    if df_housingNew['ocean_proximity'][i] == \"NEAR BAY\":\n",
    "        df_housingNew['ocean_proximity'][i] = 0.0\n",
    "    elif df_housingNew['ocean_proximity'][i] == \"<1H OCEAN\":\n",
    "        df_housingNew['ocean_proximity'][i] = 0.5\n",
    "    else:\n",
    "        df_housingNew['ocean_proximity'][i] = 1.0\n",
    "df_housingNew = df_housingNew[['neighborhood', 'ocean_proximity', 'median_house_value', 'housing_median_age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define a function to transform all int to float\n",
    "\n",
    "def toFloat(num):\n",
    "    return np.float(num)\n",
    "#apply the 'toFloat' function to the 'ocean_proximity' column in df_housingNew\n",
    "df_housingNew['ocean_proximity'] = df_housingNew['ocean_proximity'].apply(toFloat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregate the data with the same neighborhood and calculate their mean values\n",
    "\n",
    "df_housingNew = round(df_housingNew.groupby('neighborhood').mean(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the scatterplot representing the relationship between ocean proximity and house value\n",
    "\n",
    "fd = pd.plotting.scatter_matrix(df_housingNew[['ocean_proximity', 'median_house_value']], diagonal='kde', figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>\n",
    "The graph above shows the correlation between the ocean proximity of house and the median house value in different neighborhoods. The left bottom graph with ocean proximity on the x-axis and median house value on the y-axis is the main graph to analyze. There are three vertical \"lines\" because in each neighborhood the houses have nearly the same ocean proximity with few exceptions, which are the dots in-between. From the graph, we could easily find out that the inland houses have much lower median house values than the nearby and within-an-hour groups. This statement affirms our hypothesis that the inland houses have lower prices than those ones close by. However, we notice that the price of the \"nearby\" and \"within-an-hour\" houses are very close to each other, and the \"nearby\" group is slightly lower than the \"within-an-hour\" group. We think that the house age may be affecting the price as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make scatterplot representing the relationship among ocean proximity, house value and house age\n",
    "\n",
    "fd1 = pd.plotting.scatter_matrix(df_housingNew[['ocean_proximity', 'median_house_value', 'housing_median_age']], diagonal='kde',figsize=(8, 8), color=\"maroon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>\n",
    "From the bottom-left graph in the second graph, we find out that the dots representing \"nearby\" houses concentrate more at the top, which means that they are older than the ones that are \"within-an-hour\" group, which concentrate more at the middle part. Also, the housing median age has a week negative correlation with the median house value, so we deduce that the \"nearby\" group is slightly cheaper than \"within-an-hour\" because of the house age.<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong><h3>Data Cleaning and Analysis (Part2)</h3></strong><br>\n",
    "This second dataset is used to evaluate the correlation between time period and rent. Thus, we drop the irrelevant columns and 3 months that are too early to count. We also calculate the average rent of all regions in one month. Then we access the data using polyfit and scatterplot. We make a number of scatterplots because we need the relationship both between time period in total and the rent, and between the month and rent within each year. Based on our own experience in La Jolla, we consider the middle of year as the time period with the highest house rent. As a result, we locate the data for La Jolla specifically and evaluate the proposed correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#switch to antoher set of data to deduce the relationship between time period and rent\n",
    "\n",
    "df_temp = df_neighborhood.drop(['RegionName','RegionID','City','State','Metro','CountyName','SizeRank','2010-10','2010-11','2010-12'], axis=1)\n",
    "df_laJollatemp = df_laJolla.drop(['RegionName','RegionID','City','State','Metro','CountyName','SizeRank','2010-10','2010-11','2010-12'], axis=1)\n",
    "monthList = list(df_temp.columns.values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make scatterplot representing the relationship among four different months\n",
    "\n",
    "fd2 = pd.plotting.scatter_matrix(df_temp[[ '2011-01', '2011-02','2017-01','2017-02']], diagonal=\"kde\", color=\"cornflowerblue\", figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the average price of all different regions at different time periods\n",
    "\n",
    "averagelist = df_temp.mean(axis=0).tolist()\n",
    "laJollaList = df_laJollatemp.mean(axis=0).tolist()\n",
    "df_averagelist = pd.DataFrame(averagelist, columns=['Rent'])\n",
    "df_laJollaList = pd.DataFrame(laJollaList, columns=['Rent'])\n",
    "df_averagelist = df_averagelist.reset_index()\n",
    "df_laJollaList = df_laJollaList.reset_index()\n",
    "df_averagelist.columns = ['Month','Rent']\n",
    "df_laJollaList.columns = ['Month','Rent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mutiply original ratios with 10000 to transform them into ints\n",
    "\n",
    "df_averagelist10000 = pd.DataFrame(0, index=np.arange(len(df_averagelist)), columns=['Ratio10000'])\n",
    "df_laJollaList10000 = pd.DataFrame(0, index=np.arange(len(df_laJollaList)), columns=['Ratio10000'])\n",
    "for i in range(0, len(df_averagelist)):\n",
    "    df_averagelist10000['Ratio10000'][i] = df_averagelist['Rent'][i] *10000\n",
    "for i in range(0, len(df_laJollaList)):\n",
    "    df_laJollaList10000['Ratio10000'][i] = df_laJollaList['Rent'][i] *10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#swap the columns of two dataframes\n",
    "\n",
    "columnsTitles=[\"Month\",\"Ratio10000\"]    \n",
    "\n",
    "df_averagelist10000['Month'] = df_averagelist['Month']\n",
    "df_averagelist10000 = df_averagelist10000.reindex(columns=columnsTitles)\n",
    "\n",
    "df_laJollaList10000['Month'] = df_laJollaList['Month']\n",
    "df_laJollaList10000 = df_laJollaList10000.reindex(columns=columnsTitles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we could use this to construct a linear model, but in search of more precision, \n",
    "# we turn to scatterplot and linear regression to calculate the p value\n",
    "a1, b1 = np.polyfit(df_averagelist10000['Month'], df_averagelist10000['Ratio10000'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#make scatterplot representing the relationship between Month and Ratio10000 in df_averagelist10000\n",
    "\n",
    "fd3 = pd.plotting.scatter_matrix(df_averagelist10000[[ 'Month','Ratio10000']], diagonal='kde', color='#00b36b', figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate the dataframe df_averagelist10000 into 7 years\n",
    "year11 = df_averagelist10000[0:11]\n",
    "year12 = df_averagelist10000[12:23]\n",
    "year13 = df_averagelist10000[24:35]\n",
    "year14 = df_averagelist10000[36:47]\n",
    "year15 = df_averagelist10000[48:59]\n",
    "year16 = df_averagelist10000[60:71]\n",
    "year17 = df_averagelist10000[72:83]\n",
    "\n",
    "#make scatterplot representing the relationship between Month and Ratio10000 in each year\n",
    "yr_11 = pd.plotting.scatter_matrix(year11, figsize=(4, 4), color=\"firebrick\")\n",
    "yr_12 = pd.plotting.scatter_matrix(year12, figsize=(4, 4), color=\"firebrick\")\n",
    "yr_13 = pd.plotting.scatter_matrix(year13, figsize=(4, 4), color=\"firebrick\")\n",
    "yr_14 = pd.plotting.scatter_matrix(year14, figsize=(4, 4), color=\"firebrick\")\n",
    "yr_15 = pd.plotting.scatter_matrix(year15, figsize=(4, 4), color=\"firebrick\")\n",
    "yr_16 = pd.plotting.scatter_matrix(year16, figsize=(4, 4), color=\"firebrick\")\n",
    "yr_17 = pd.plotting.scatter_matrix(year17, figsize=(4, 4), color=\"firebrick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make scatterplot representing the relationship between time and Ratio10000 in df_laJollaList10000\n",
    "\n",
    "fd5 = pd.plotting.scatter_matrix(df_laJollaList10000[[ 'Month','Ratio10000']], color=\"goldenrod\", figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make scatterplot representing the relationship between month and Ratio10000 in each year\n",
    "yr_11_laJolla = pd.plotting.scatter_matrix(df_laJollaList10000[0:11], figsize=(4, 4), color='midnightblue')\n",
    "yr_12_laJolla = pd.plotting.scatter_matrix(df_laJollaList10000[12:23], figsize=(4, 4), color='midnightblue')\n",
    "yr_13_laJolla = pd.plotting.scatter_matrix(df_laJollaList10000[24:35], figsize=(4, 4), color='midnightblue')\n",
    "yr_14_laJolla = pd.plotting.scatter_matrix(df_laJollaList10000[36:47], figsize=(4, 4), color='midnightblue')\n",
    "yr_15_laJolla = pd.plotting.scatter_matrix(df_laJollaList10000[48:59], figsize=(4, 4), color='midnightblue')\n",
    "yr_16_laJolla = pd.plotting.scatter_matrix(df_laJollaList10000[60:71], figsize=(4, 4), color='midnightblue')\n",
    "yr_17_laJolla = pd.plotting.scatter_matrix(df_laJollaList10000[72:83], figsize=(4, 4), color='midnightblue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong><h3>Data Analysis (Part3)</h3></strong><br>\n",
    "The third dataset is used to find the relationship between average room number per house and the median house value. Our hypothesis is that average room number/house is positively correlated to the median house income, thus we need to make a linear regression line and its P-value for the two sets of data. \n",
    "To achieve our goal, we first created a new column with average room number/house by dividing the total rooms with total households, then we plotted a linear regression line using scipy.stats, and printed out the slope and P-value. The slope we got is 7086, which means that the average room number/house and median house value are positively correlated, and the P-value is very close to 0, which means that we reject the null hypothesis. In conclusion, the more room per house the neighborhood has, the more expensive housing price at the area will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#switch to antoher set of data to deduce the relationship between the average number of rooms and rent\n",
    "df_rooms = df_housing\n",
    "df_rooms['rooms/house'] = df_rooms['total_rooms'] / df_rooms['households']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use statistics to acquire the p value to the hypothesis that the average number of rooms correlates to the rent\n",
    "\n",
    "from scipy import stats\n",
    "x=df_rooms['rooms/house']\n",
    "y=df_rooms['median_house_value']\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "print(slope, p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong><h3>Privacy and Ethics</h3></strong><br>\n",
    "The two datasets are both public sources, so we do have permission to use them for our own analysis on related subjects. Since we drop a number of columns and utilize only ocean proximity, house value, house age, neighborhood names, time, rent-to-value ratio, total room numbers, and total households to proceed our analysis, its process does not involve any personal information such as name, phone number or zip-code. Therefore, the privacy concerns have been tackled wtih.<br>\n",
    "<br>\n",
    "One potential bias that our dataset has is that its only geographical concern is the proximity to ocean. There will be other factors such as neighbor crime rate, or other geographical features such as proximity to lake, mountain or nearest elementary school that affect housing prices. We plan to focus on finding the correlation between house pricing, the amount of bedrooms and use simply the proximity to ocean as an additional factor to minimize the influence of this potentially biased factor on our prediction model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong><h3>Conclusion</h3></strong><br>\n",
    "In short, our hypothesis states that housing price is positively correlated to the average number of rooms per household, and the proximity to the ocean. Also, housing price may be higher in specific time periods in a year. \n",
    "\n",
    "In conclusion, we affirm that the housing price is strongly positively correlated to the average number of rooms per household. The proximity to the ocean and the house value is also positively correlated, given the fact that the house age is also involved, resulting in the decrease of the price of houses nearby the ocean. We reject the hypothesis that the housing price is related to time periods in one year. In fact, there is no pattern of the trend of the housing price in a year. However, we found out that the housing price has been increasing in general since 2011.\n",
    "\n",
    "Throughout our analysis of three factors affecting the house price, we manage to provide suggestions for those who need to rent or purchase a house from three different angles. For example, if one wants to rent a house in proximity to the ocean while he also wants to lower the rent cost, then it is preferred for him to rent either an older house or one with fewer rooms. Additionally, one should not attach too much significance to the time period he signs the contract since the trend of house price fluctuates randomly within a year. If one wants to purchase a house, he should not hesitate for too long since our data shows that the average housing price has been growing. We also studied the housing price in La Jolla specifically and found out that the housing price around La Jolla is relatively stable these years. So for us students in UCSD, it is beneficial to rent a house in La Jolla in recent times.\n",
    "\n",
    "The biggest flaw in our research turns out to be the fact that the three factors we dive into are not considered as a whole when we try to predict certain house prices. This outcome originates from our datasets which are processed individually. We intended to merge them initially, but the neighborhoods or regions in each dataset are not consistent. Admittedly, the intrinsic characteristics of house price lead to the difficulty of analyzing the factors that affect it. As a result, our research is just a glimpse into the field of the housing market. It reveals that with more and more datasets entering the analysis, the simplified model of house prices will finally be constructed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
